name: CI/CD Pipeline

on:
  push:
    branches: [ main, dev, 'feature/**' ]
  pull_request:
    branches: [ main, dev ]
  workflow_dispatch:  # Allow manual trigger

env:
  BUILD_TYPE: Release
  CMAKE_VERSION: '3.25'

jobs:
  build-and-test:
    name: Build & Test (Windows)
    runs-on: windows-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        submodules: recursive
        fetch-depth: 0  # Full history for accurate versioning

    - name: Setup MSVC
      uses: microsoft/setup-msbuild@v2
      with:
        vs-version: '[17.0,18.0)'  # Visual Studio 2022

    - name: Setup CMake
      uses: jwlawson/actions-setup-cmake@v2
      with:
        cmake-version: ${{ env.CMAKE_VERSION }}

    - name: Cache CMake dependencies
      uses: actions/cache@v4
      with:
        path: |
          build/_deps
          build/lib
        key: ${{ runner.os }}-cmake-${{ hashFiles('**/CMakeLists.txt') }}
        restore-keys: |
          ${{ runner.os }}-cmake-

    - name: Configure CMake
      run: |
        cmake -B build -S . `
          -DCMAKE_BUILD_TYPE=${{ env.BUILD_TYPE }} `
          -DBUILD_TESTS=ON `
          -DENABLE_TENSORRT=OFF `
          -DENABLE_ARDUINO=OFF

    - name: Build project
      run: cmake --build build --config ${{ env.BUILD_TYPE }} -j

    - name: Run unit tests
      run: |
        cd build/bin/${{ env.BUILD_TYPE }}
        ./unit_tests.exe --reporter compact --success
      continue-on-error: false

    - name: Run integration tests
      run: |
        cd build/bin/${{ env.BUILD_TYPE }}
        ./integration_tests.exe --reporter compact --success
      continue-on-error: false

    - name: Run benchmark (Performance Regression)
      id: benchmark
      run: |
        cd build/bin/${{ env.BUILD_TYPE }}
        ./macroman-bench.exe `
          --frames 200 `
          --threshold-avg-fps 90 `
          --threshold-p95-latency 12.0 `
          --threshold-p99-latency 15.0 `
          --verbose
      continue-on-error: true

    - name: Check benchmark results
      if: steps.benchmark.outcome == 'failure'
      run: |
        echo "::error::Benchmark failed - Performance regression detected"
        exit 1

    - name: Upload test artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ github.run_number }}
        path: |
          build/bin/${{ env.BUILD_TYPE }}/*.exe
          build/bin/${{ env.BUILD_TYPE }}/*.dll
        retention-days: 7

    - name: Upload benchmark results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ github.run_number }}
        path: |
          build/bin/${{ env.BUILD_TYPE }}/macroman-bench.exe
        retention-days: 14

  code-quality:
    name: Code Quality Checks
    runs-on: windows-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Check for TODO/FIXME comments
      run: |
        $todos = Get-ChildItem -Recurse -Include *.cpp,*.h | Select-String -Pattern "TODO|FIXME" | Measure-Object
        echo "Found $($todos.Count) TODO/FIXME comments"
        if ($todos.Count -gt 100) {
          echo "::warning::High number of TODO/FIXME comments ($($todos.Count))"
        }

    - name: Check file sizes
      run: |
        Get-ChildItem -Recurse -Include *.cpp,*.h | Where-Object { $_.Length -gt 1000000 } | ForEach-Object {
          echo "::warning::Large file detected: $($_.Name) ($([math]::Round($_.Length/1KB, 2)) KB)"
        }

    - name: Verify documentation naming
      run: |
        $sunoneRefs = Get-ChildItem -Recurse -Include *.md | Select-String -Pattern "sunone-bench" | Measure-Object
        if ($sunoneRefs.Count -gt 0) {
          echo "::error::Found $($sunoneRefs.Count) references to 'sunone-bench' instead of 'macroman-bench'"
          exit 1
        } else {
          echo "âœ“ All documentation uses correct naming (macroman-bench)"
        }

  performance-tracking:
    name: Performance Tracking
    runs-on: windows-latest
    needs: build-and-test

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup CMake
      uses: jwlawson/actions-setup-cmake@v2
      with:
        cmake-version: ${{ env.CMAKE_VERSION }}

    - name: Configure and build
      run: |
        cmake -B build -S . -DCMAKE_BUILD_TYPE=${{ env.BUILD_TYPE }} -DBUILD_TESTS=ON
        cmake --build build --config ${{ env.BUILD_TYPE }} --target macroman-bench -j

    - name: Run extended benchmark
      run: |
        cd build/bin/${{ env.BUILD_TYPE }}
        ./macroman-bench.exe `
          --frames 500 `
          --threshold-avg-fps 100 `
          --threshold-p95-latency 12.0 `
          --threshold-p99-latency 15.0 `
          --verbose > benchmark_output.txt

        # Display results
        Get-Content benchmark_output.txt

    - name: Extract performance metrics
      run: |
        $output = Get-Content build/bin/${{ env.BUILD_TYPE }}/benchmark_output.txt -Raw

        # Extract FPS (example parsing - adjust based on actual output format)
        if ($output -match "Average FPS:\s+([\d.]+)") {
          $fps = $matches[1]
          echo "BENCHMARK_FPS=$fps" >> $env:GITHUB_ENV
          echo "::notice::Benchmark FPS: $fps"
        }

        if ($output -match "P95:\s+([\d.]+)") {
          $p95 = $matches[1]
          echo "BENCHMARK_P95=$p95" >> $env:GITHUB_ENV
          echo "::notice::Benchmark P95 Latency: ${p95}ms"
        }

    - name: Comment PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const output = require('fs').readFileSync('build/bin/Release/benchmark_output.txt', 'utf8');

          const comment = `## ðŸš€ Performance Benchmark Results

          **Commit:** ${context.sha.substring(0, 7)}
          **Branch:** ${context.ref}

          ### Results
          \`\`\`
          ${output}
          \`\`\`

          _Automated benchmark from CI/CD pipeline_
          `;

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

  release:
    name: Create Release Build
    runs-on: windows-latest
    needs: [build-and-test, code-quality]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        submodules: recursive

    - name: Setup CMake
      uses: jwlawson/actions-setup-cmake@v2
      with:
        cmake-version: ${{ env.CMAKE_VERSION }}

    - name: Configure CMake (Release)
      run: |
        cmake -B build -S . `
          -DCMAKE_BUILD_TYPE=Release `
          -DBUILD_TESTS=OFF `
          -DENABLE_TENSORRT=ON `
          -DENABLE_ARDUINO=OFF

    - name: Build Release
      run: cmake --build build --config Release -j

    - name: Package binaries
      run: |
        mkdir release
        Copy-Item build/bin/Release/macroman_aimbot.exe release/
        Copy-Item build/bin/Release/macroman_config.exe release/
        Copy-Item build/bin/Release/*.dll release/
        Copy-Item -Recurse build/bin/assets release/ -ErrorAction SilentlyContinue

        # Create README for release
        @"
        MacroMan AI Aimbot - Release Build

        Build: ${{ github.run_number }}
        Commit: ${{ github.sha }}
        Date: $(Get-Date -Format "yyyy-MM-dd HH:mm:ss")

        Files:
        - macroman_aimbot.exe: Main application
        - macroman_config.exe: Configuration UI
        - *.dll: Required runtime libraries
        - assets/: Models and resources
        "@ | Out-File release/README.txt

    - name: Upload release artifacts
      uses: actions/upload-artifact@v4
      with:
        name: macroman-aimbot-${{ github.run_number }}
        path: release/
        retention-days: 30
